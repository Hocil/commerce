import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker
import seaborn as sns
import calendar
import numpy as np
import matplotlib.patheffects as pe
from matplotlib.ticker import PercentFormatter

import matplotlib.pyplot as plt
from matplotlib import font_manager, rc

# ìœˆë„ìš° í°íŠ¸ ì§€ì •
font_path = "C:/Windows/Fonts/malgun.ttf"
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)


# from data import load_all_data
# all_data = load_all_data()


# ---- [ë‚´ load_all_data ëŒ€ì²´ í•¨ìˆ˜ ì¶”ê°€] ----
@st.cache_data
def load_all_data(base_path="data/"):
    # 1. CSV ë¡œë“œ
    users = pd.read_csv(base_path + "users.csv")
    products = pd.read_csv(base_path + "products.csv")
    orders = pd.read_csv(base_path + "orders.csv")
    order_items = pd.read_csv(base_path + "order_items.csv")
    events = pd.read_csv(base_path + "events_sample.csv")
    inventory_items = pd.read_csv(base_path + "inventory_items.csv")

    # 2. ë‚ ì§œ ë³€í™˜
    date_cols = {
        "users": ["created_at"],
        "orders": ["created_at", "returned_at", "shipped_at", "delivered_at"],
        "order_items": ["created_at", "shipped_at", "delivered_at", "returned_at"],
        "events": ["created_at"],
        "inventory_items": ["created_at", "sold_at"]
    }
    dfs = {
        "users": users,
        "orders": orders,
        "order_items": order_items,
        "events": events,
        "inventory_items": inventory_items
    }
    for df_name, cols in date_cols.items():
        for col in cols:
            dfs[df_name][col] = pd.to_datetime(dfs[df_name][col], errors="coerce")

    # 3. 2023 ë°ì´í„°ë§Œ í•„í„°ë§
    users = users[(users['created_at'] >= "2023-01-01") & (users['created_at'] <= "2023-12-31")]
    orders = orders[(orders['created_at'] >= "2023-01-01") & (orders['created_at'] <= "2023-12-31")]
    order_items = order_items[(order_items['created_at'] >= "2023-01-01") & (order_items['created_at'] <= "2023-12-31")]
    events = events[(events['created_at'] >= "2023-01-01") & (events['created_at'] <= "2023-12-31")]
    inventory_items = inventory_items[(inventory_items['created_at'] >= "2023-01-01") & (inventory_items['created_at'] <= "2023-12-31")]

    return {
        "users": users,
        "products": products,
        "orders": orders,
        "order_items": order_items,
        "events": events,
        "inventory_items": inventory_items
    }



@st.cache_data
def create_purchase_distribution_chart(order_items_df):
    """ì‚¬ìš©ìžë³„ êµ¬ë§¤ íšŸìˆ˜ ë¶„í¬ë¥¼ ê³„ì‚°í•˜ê³  ë§‰ëŒ€ê·¸ëž˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    # 'Complete' ìƒíƒœì¸ ì£¼ë¬¸ë§Œ í•„í„°ë§
    completed_orders = order_items_df[order_items_df['status'] == 'Complete']
    
    if completed_orders.empty:
        st.warning("ë¶„ì„í•  ì™„ë£Œëœ ì£¼ë¬¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
        
    # ì‚¬ìš©ìžë³„ êµ¬ë§¤ íšŸìˆ˜ ê³„ì‚° (user_idë³„ë¡œ ê·¸ë£¹í™” í›„ order_idì˜ ê³ ìœ  ê°œìˆ˜ ê³„ì‚°)
    user_purchase_counts = completed_orders.groupby('user_id')['order_id'].nunique()
    
    # êµ¬ë§¤ íšŸìˆ˜ë³„ ì‚¬ìš©ìž ìˆ˜ ë¶„í¬ ê³„ì‚°
    purchase_dist = user_purchase_counts.value_counts().sort_index()

    # --- Matplotlib ì°¨íŠ¸ ìƒì„± ---
    fig, ax = plt.subplots(figsize=(12, 7))
    purchase_dist.plot(kind='bar', ax=ax, color='skyblue')
    
    ax.set_title("ì‚¬ìš©ìžë³„ êµ¬ë§¤ íšŸìˆ˜ ë¶„í¬", fontsize=18, fontweight='bold')
    ax.set_xlabel("ì‚¬ìš©ìžë‹¹ ì´ êµ¬ë§¤ íšŸìˆ˜", fontsize=12)
    ax.set_ylabel("ì‚¬ìš©ìž ìˆ˜", fontsize=12)
    ax.tick_params(axis='x', rotation=0)
    ax.grid(axis='y', linestyle='--', alpha=0.7)
    
    fig.tight_layout()
    
    return fig, purchase_dist

@st.cache_data
def create_retention_heatmap(order_items_df, show_annotations=True):
    """
    ì£¼ë¬¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì½”í˜¸íŠ¸ ë¦¬í…ì…˜ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ížˆíŠ¸ë§µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # 'Complete' ìƒíƒœì¸ ì£¼ë¬¸ë§Œ í•„í„°ë§
    valid_orders = order_items_df[order_items_df['status'] == 'Complete'].copy()

    if valid_orders.empty:
        return None, None

    # --- ì½”í˜¸íŠ¸ ê³„ì‚° ë¡œì§ (ì œê³µí•´ì£¼ì‹  ì½”ë“œ ê¸°ë°˜) ---
    valid_orders['order_month'] = valid_orders['created_at'].dt.to_period('M').dt.to_timestamp()
    
    first_purchase = valid_orders.groupby('user_id')['order_month'].min().rename('order_month_cohort')
    valid_orders = valid_orders.join(first_purchase, on='user_id')
    
    # ì½”í˜¸íŠ¸ ì›”ì´ ì—†ëŠ” ê²½ìš°(join ì‹¤íŒ¨) ë°ì´í„° ì œì™¸
    valid_orders.dropna(subset=['order_month_cohort'], inplace=True)

    valid_orders['cohort_index'] = (
        (valid_orders['order_month'].dt.year - valid_orders['order_month_cohort'].dt.year) * 12 +
        (valid_orders['order_month'].dt.month - valid_orders['order_month_cohort'].dt.month)
    )
    
    cohort_pivot = valid_orders.groupby(['order_month_cohort', 'cohort_index'])['user_id'].nunique().reset_index()
    
    cohort_size = cohort_pivot[cohort_pivot['cohort_index'] == 0][['order_month_cohort', 'user_id']]
    cohort_pivot = cohort_pivot.merge(cohort_size, on='order_month_cohort', suffixes=('', '_cohort_size'))
    
    cohort_pivot['retention'] = cohort_pivot['user_id'] / cohort_pivot['user_id_cohort_size']

    cohort_table = cohort_pivot.pivot_table(index="order_month_cohort",
                                            columns="cohort_index",
                                            values="retention")
    

    # 1. ì‹œê°í™”í•  ë°ì´í„°ì—ì„œ ì²« ë²ˆì§¸ ì—´ (0ê°œì›”ì°¨)ì„ ì œì™¸í•©ë‹ˆë‹¤.
    # .iloc[:, 1:]ëŠ” ëª¨ë“  í–‰ê³¼, 1ë²ˆ ì¸ë±ìŠ¤(ë‘ ë²ˆì§¸) ì—´ë¶€í„° ëê¹Œì§€ì˜ ì—´ì„ ì„ íƒí•©ë‹ˆë‹¤.
    heatmap_data = cohort_table.iloc[:, 1:]

    # 2. ì£¼ì„(annot) ë°ì´í„°ë„ ë™ì¼í•˜ê²Œ ì²« ë²ˆì§¸ ì—´ì„ ì œì™¸í•˜ê³  ìƒì„±í•©ë‹ˆë‹¤.
    annot_data = None
    if show_annotations:
        annot_data = heatmap_data.copy()
        annot_data[annot_data == 0] = np.nan

    # --- Matplotlib ížˆíŠ¸ë§µ ìƒì„± ---
    fig, ax = plt.subplots(figsize=(14, 8))
    
    sns.heatmap(
        data=heatmap_data,         # âœ¨ ìˆ˜ì •: ìŠ¬ë¼ì´ì‹±ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©
        annot=annot_data,          # âœ¨ ìˆ˜ì •: ìŠ¬ë¼ì´ì‹±ëœ ì£¼ì„ ë°ì´í„°ë¥¼ ì‚¬ìš©
        fmt=".1%",
        cmap="Blues", 
        linewidths=.5,
        ax=ax
    )
    
    ax.set_title("ê³ ê° ë¦¬í…ì…˜ ì½”í˜¸íŠ¸ ë¶„ì„ ížˆíŠ¸ë§µ", fontsize=18, fontweight='bold')
    ax.set_ylabel("ì²« êµ¬ë§¤ì›” (Cohort)", fontsize=12)
    ax.set_xlabel("ìž¬êµ¬ë§¤ê¹Œì§€ ê±¸ë¦° ê°œì›” ìˆ˜", fontsize=12)
    
    # Yì¶• ë‚ ì§œ í¬ë§· ë³€ê²½
    ax.set_yticklabels([d.strftime('%Y-%m') for d in cohort_table.index])
    
    fig.tight_layout()
    
    return fig, cohort_table


def create_category_cohort_heatmap(order_items_df, products_df, category, show_annotations=True):
    """
    ì„ íƒëœ ì¹´í…Œê³ ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì½”í˜¸íŠ¸ ë¦¬í…ì…˜ ížˆíŠ¸ë§µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    valid_orders = order_items_df[order_items_df['status'] == 'Complete'].copy()

    orders_with_products = valid_orders.merge(
        products_df[['id', 'category']],
        left_on='product_id',
        right_on='id',
        how='left'
    )
    category_orders = orders_with_products[orders_with_products['category'] == category].copy()
    
    if category_orders.empty:
        return None, None
    
    category_orders['created_at'] = category_orders['created_at'].dt.tz_localize(None)
    category_orders['order_month'] = category_orders['created_at'].dt.to_period('M').dt.to_timestamp()
    
    first_purchase = category_orders.groupby('user_id')['order_month'].min().rename('order_month_cohort')
    category_orders = category_orders.join(first_purchase, on='user_id')
    category_orders.dropna(subset=['order_month_cohort'], inplace=True)
    
    # âœ¨ ìˆ˜ì •: ì—°ë„ í•„í„°ë§ ë¡œì§ ì œê±°
    # category_orders = category_orders[category_orders['order_month_cohort'].dt.year == year]

    if category_orders.empty:
        return None, None

    category_orders['cohort_index'] = ((category_orders['order_month'].dt.year - category_orders['order_month_cohort'].dt.year) * 12 + (category_orders['order_month'].dt.month - category_orders['order_month_cohort'].dt.month))
    
    cohort_pivot = category_orders.groupby(['order_month_cohort', 'cohort_index'])['user_id'].nunique().reset_index()
    cohort_size = cohort_pivot[cohort_pivot['cohort_index'] == 0][['order_month_cohort', 'user_id']]
    cohort_pivot = cohort_pivot.merge(cohort_size, on='order_month_cohort', suffixes=('', '_cohort_size'))
    cohort_pivot['retention'] = cohort_pivot['user_id'] / cohort_pivot['user_id_cohort_size']
    cohort_table = cohort_pivot.pivot_table(index="order_month_cohort", columns="cohort_index", values="retention")

    heatmap_data = cohort_table.iloc[:, 1:]
    
    annot_data = None
    if show_annotations:
        annot_data = heatmap_data.copy()
        annot_data[annot_data == 0] = np.nan

    fig, ax = plt.subplots(figsize=(14, 8))
    sns.heatmap(data=heatmap_data, annot=annot_data, fmt=".1%", cmap="Blues", linewidths=.5, ax=ax)
    
    ax.set_title(f"'{category}' ì¹´í…Œê³ ë¦¬ ê³ ê° ë¦¬í…ì…˜ ížˆíŠ¸ë§µ", fontsize=18, fontweight='bold') # âœ¨ ìˆ˜ì •: ì œëª©ì—ì„œ ì—°ë„ ì œê±°
    ax.set_ylabel("ì²« êµ¬ë§¤ì›” (Cohort)", fontsize=12)
    ax.set_xlabel("ìž¬êµ¬ë§¤ê¹Œì§€ ê±¸ë¦° ê°œì›” ìˆ˜", fontsize=12)
    ax.set_yticklabels([d.strftime('%Y-%m') for d in heatmap_data.index])
    fig.tight_layout()
    
    return fig, cohort_table

@st.cache_data
# âœ¨ ìˆ˜ì •: year íŒŒë¼ë¯¸í„° ì œê±°
def create_advanced_cohort_heatmap(orders_df, max_age_m, show_annotations=True):
    """
    ì •êµí•œ ë°©ì‹ìœ¼ë¡œ ì½”í˜¸íŠ¸ ìž¬êµ¬ë§¤ìœ¨ì„ ê³„ì‚°í•˜ê³  ížˆíŠ¸ë§µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # (ì•žë¶€ë¶„ ë¡œì§ì€ ë™ì¼)
    use_cols = [c for c in ['user_id', 'created_at', 'status'] if c in orders_df.columns]
    if not use_cols or 'user_id' not in use_cols or 'created_at' not in use_cols:
        st.warning("ë¶„ì„ì— í•„ìš”í•œ 'user_id', 'created_at' ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    src = orders_df.loc[:, use_cols].copy()
    if 'status' in src.columns:
        src['status'] = src['status'].astype(str).str.strip().str.lower()
        src = src[src['status'] == 'complete']
    if src.empty:
        st.warning("ìƒíƒœê°€ 'Complete'ì¸ ì£¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    src = src[src['user_id'].notna()].copy()
    src['created_at'] = pd.to_datetime(src['created_at'], utc=True, errors='coerce')
    src = src.dropna(subset=['created_at'])
    if src.empty:
        st.warning("ìœ íš¨í•œ ì£¼ë¬¸ ì‹œê°„ì´ ìžˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    last_month = src['created_at'].dt.to_period('M').max()
    last_i = last_month.year * 12 + last_month.month

    # ì‚¬ìš©ìžë³„ ì²« êµ¬ë§¤ì›” ì‚°ì¶œ
    first = src.groupby('user_id', as_index=False)['created_at'].min().rename(columns={'created_at':'first_time'})
    first['cohort_month'] = first['first_time'].dt.to_period('M')
    
    # âœ¨ ìˆ˜ì •: ì—°ë„ í•„í„°ë§ ë¡œì§ ì œê±° (ëª¨ë“  ì½”í˜¸íŠ¸ ì‚¬ìš©)
    # first_year = first[first['cohort_year'] == year].copy()
    # if first_year.empty: ...
        
    cohort_size = first.groupby('cohort_month')['user_id'].nunique().rename('cohort_size')

    # ì£¼ë¬¸ì— ì½”í˜¸íŠ¸ ë¼ë²¨ ë¶™ì´ê¸°
    lab = src.merge(first[['user_id','cohort_month']], on='user_id', how='inner')
    if lab.empty:
        st.warning("ì½”í˜¸íŠ¸ ê·¸ë£¹ì˜ ì£¼ë¬¸ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    lab['order_month'] = lab['created_at'].dt.to_period('M')

    # (ì´í•˜ ê³„ì‚° ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼)
    cm_i = lab['cohort_month'].dt.year * 12 + lab['cohort_month'].dt.month
    om_i = lab['order_month'].dt.year * 12 + lab['order_month'].dt.month
    lab['cohort_age_m'] = om_i - cm_i
    lab = lab[(lab['cohort_age_m'] >= 0) & (lab['cohort_age_m'] <= max_age_m)].copy()

    cohort_months = np.sort(first['cohort_month'].unique()) # âœ¨ ìˆ˜ì •: first_year -> first
    age_vals = np.arange(0, max_age_m + 1)
    grid = pd.MultiIndex.from_product([cohort_months, age_vals], names=['cohort_month','cohort_age_m']).to_frame(index=False)
    grid['cm_i'] = grid['cohort_month'].dt.year * 12 + grid['cohort_month'].dt.month
    grid['order_i'] = grid['cm_i'] + grid['cohort_age_m']
    grid = grid[grid['order_i'] <= last_i].drop(columns=['cm_i','order_i'])

    counts = lab.groupby(['cohort_month','cohort_age_m'])['user_id'].nunique().rename('active_users').reset_index()
    counts = grid.merge(counts, on=['cohort_month','cohort_age_m'], how='left').fillna({'active_users': 0})

    counts = counts.merge(cohort_size, on='cohort_month', how='left')
    counts['retention_rate'] = counts['active_users'] / counts['cohort_size']

    heat = counts.pivot(index='cohort_month', columns='cohort_age_m', values='retention_rate')
    heat = heat.sort_index().sort_index(axis=1)
    if 0 in heat.columns:
        heat = heat.loc[:, heat.columns != 0]

    idx_period = heat.index.copy()
    base_labels = idx_period.astype(str)
    n_map = cohort_size.reindex(idx_period).fillna(0).astype(int).map(lambda x: f"{x:,}")
    row_labels = base_labels + ' Â· N=' + n_map
    heat.index = row_labels
    heat_pct = heat * 100

    # ížˆíŠ¸ë§µ ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(12, max(4, 0.6 * len(heat_pct.index))))
    sns.heatmap(
        heat_pct, annot=show_annotations, fmt=".1f", cmap="Blues",
        cbar_kws={'label': 'ìž¬êµ¬ë§¤ìœ¨ (%)'}, linewidths=.3, linecolor='white', ax=ax
    )
    ax.set_title("ì›”ë³„ ì½”í˜¸íŠ¸ ìž¬êµ¬ë§¤ìœ¨ ížˆíŠ¸ë§µ (Ageâ‰¥1)", fontsize=16) # âœ¨ ìˆ˜ì •: ì œëª©ì—ì„œ ì—°ë„ ì œê±°
    ax.set_xlabel("ì²« êµ¬ë§¤ í›„ ê²½ê³¼ ê°œì›” ìˆ˜")
    ax.set_ylabel("ì½”í˜¸íŠ¸ ì›” (ì²« êµ¬ë§¤ì›” Â· N=í‘œë³¸í¬ê¸°)")
    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)
    fig.tight_layout()

    return fig, heat

def create_repeat_purchaser_chart(orders_df):
    """
    2023ë…„ ì›”ë³„ ìž¬êµ¬ë§¤ìž ë¹„ìœ¨ì„ ë¶„ì„í•˜ê³  ì´ì¤‘ ì¶• ê·¸ëž˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # (ì•žë¶€ë¶„ ë°ì´í„° ì²˜ë¦¬ ë¡œì§ì€ ë™ì¼)
    use_cols = [c for c in ['user_id', 'created_at', 'status'] if c in orders_df.columns]
    orders = orders_df.loc[:, use_cols].copy()
    orders = orders[orders['user_id'].notna()].copy()
    orders['created_at'] = pd.to_datetime(orders['created_at'], utc=True, errors='coerce')
    orders = orders.dropna(subset=['created_at'])
    if 'status' in orders.columns:
        orders['status'] = orders['status'].astype(str).str.strip().str.lower()
        orders = orders[orders['status'] == 'complete'].drop(columns=['status'])
    if orders.empty:
        st.warning("ìƒíƒœê°€ 'Complete'ì¸ ì£¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    first_time = orders.groupby('user_id', as_index=False)['created_at'].min().rename(columns={'created_at': 'first_time'})
    first_time['cohort_month'] = first_time['first_time'].dt.to_period('M')
    purch = orders[['user_id','created_at']].copy()
    purch['order_month'] = purch['created_at'].dt.to_period('M')
    purch = purch.drop_duplicates(['user_id','order_month'])
    purch = purch.merge(first_time[['user_id','cohort_month']], on='user_id', how='left')
    purch['is_returning'] = purch['cohort_month'] < purch['order_month']
    by_month = purch.groupby('order_month')['is_returning'].agg(returning_users='sum', purchasers='count').sort_index()
    by_month['rate_raw'] = by_month['returning_users'] / by_month['purchasers']
    by_month['repeat_purchaser_rate'] = by_month['rate_raw'].round(3)

    # âœ¨ ìˆ˜ì •: 2023ë…„ìœ¼ë¡œ ì—°ë„ ê³ ì •
    m2023 = by_month.loc[by_month.index.year == 2023].copy()
    if m2023.empty:
        st.warning("2023ë…„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    m2023.index = m2023.index.astype(str)

    # (ì´í•˜ ì‹œê°í™” ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼)
    fig, ax1 = plt.subplots(figsize=(13, 5))
    x = np.arange(len(m2023))
    months = m2023.index.to_list()
    bars = ax1.bar(x, m2023['purchasers'], width=0.6, color='skyblue', alpha=0.9, label='ì´ êµ¬ë§¤ìž ìˆ˜')
    ax1.set_ylabel('ì´ êµ¬ë§¤ìž ìˆ˜')
    ax1.set_xlabel('ì£¼ë¬¸ì›” (YYYY-MM)')
    ax1.set_xticks(x); ax1.set_xticklabels(months, rotation=45, ha='right')
    ax2 = ax1.twinx()
    rate_pct = m2023['rate_raw'] * 100.0
    ax2.plot(x, rate_pct, marker='o', linewidth=2, color='tab:blue', markerfacecolor='white', label='ìž¬êµ¬ë§¤ìž ë¹„ìœ¨')
    ax2.set_ylabel('ìž¬êµ¬ë§¤ìž ë¹„ìœ¨ (%)')
    ax2.set_ylim(0, max(5, np.ceil(rate_pct.max()/5)*5))
    for rect, n in zip(bars, m2023['purchasers']):
        ax1.text(rect.get_x() + rect.get_width()/2, rect.get_height()*0.5, f"{int(n):,}", ha='center', va='center', color='black', fontsize=9, fontweight='bold')
    for xi, rp in zip(x, rate_pct):
        ax2.annotate(f"{rp:.1f}%", xy=(xi, rp), xytext=(0, 6), textcoords='offset points', ha='center', va='bottom', fontsize=9, color='tab:blue', bbox=dict(boxstyle='round,pad=0.2', fc='white', ec='none', alpha=0.8))
    is_nov_dec = [m.endswith(('-11','-12')) for m in months]
    is_jan_oct = [not f for f in is_nov_dec]
    if any(is_jan_oct):
        early_ret = m2023.loc[is_jan_oct, 'returning_users'].sum()
        early_tot = m2023.loc[is_jan_oct, 'purchasers'].sum()
        early_avg_w = (early_ret / early_tot) * 100.0
        ax2.hlines(early_avg_w, -0.5, len(x)-0.5, colors='gray', linestyles='dashed', linewidth=1.5, label='1-10ì›” í‰ê·  (ê°€ì¤‘)')
    if any(is_nov_dec):
        late_ret  = m2023.loc[is_nov_dec, 'returning_users'].sum()
        late_tot  = m2023.loc[is_nov_dec, 'purchasers'].sum()
        late_avg_w  = (late_ret / late_tot)  * 100.0
        ax2.hlines(late_avg_w, -0.5, len(x)-0.5, colors='orange', linestyles='dashed', linewidth=1.5, label='11-12ì›” í‰ê·  (ê°€ì¤‘)')
    fig.suptitle("2023ë…„ ì›”ë³„ ìž¬êµ¬ë§¤ìž ë¹„ìœ¨", fontsize=16, fontweight='bold') # âœ¨ ìˆ˜ì •
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left', bbox_to_anchor=(1.055, 1.0))
    fig.tight_layout(rect=[0,0,0.86,1])

    return fig, m2023

@st.cache_data
def create_weekly_cohort_heatmap(orders_df, selected_month, max_age_w, show_annotations=True):
    """
    ì„ íƒëœ ì›”ì— ì‹œìž‘ëœ ì£¼ê°„ ì½”í˜¸íŠ¸ì˜ ìž¬êµ¬ë§¤ìœ¨ì„ ë¶„ì„í•˜ê³  ížˆíŠ¸ë§µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # --- ì œê³µí•´ì£¼ì‹  ì½”ë“œ ë¡œì§ì„ ìŠ¤íŠ¸ë¦¼ë¦¿ í•¨ìˆ˜ì— ë§žê²Œ ìˆ˜ì • ---
    
    # 0) ì›ì²œ ì •ë¦¬
    use_cols = [c for c in ['user_id', 'created_at', 'status'] if c in orders_df.columns]
    src = orders_df.loc[:, use_cols].copy()
    src = src[src['user_id'].notna()].copy()
    src['created_at'] = pd.to_datetime(src['created_at'], utc=True, errors='coerce')
    src = src.dropna(subset=['created_at']).sort_values(['user_id','created_at'])
    if 'status' in src.columns:
        src['status'] = src['status'].astype(str).str.strip().str.lower()
        src = src[src['status'] == 'complete']
    if src.empty:
        st.warning("ìƒíƒœê°€ 'Complete'ì¸ ì£¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    REF = pd.Timestamp('1970-01-05', tz='UTC')
    src['week_start'] = src['created_at'].dt.normalize() - pd.to_timedelta(src['created_at'].dt.dayofweek, unit='D')
    src['week_idx'] = ((src['week_start'] - REF).dt.days // 7).astype(int)
    last_week_idx = int(src['week_idx'].max())

    # 1) ì²« êµ¬ë§¤(ì½”í˜¸íŠ¸) ê³„ì‚°
    first = src.groupby('user_id', as_index=False)['created_at'].min().rename(columns={'created_at':'first_time'})
    first['cohort_week_start'] = first['first_time'].dt.normalize() - pd.to_timedelta(first['first_time'].dt.dayofweek, unit='D')
    first['cohort_week_idx'] = ((first['cohort_week_start'] - REF).dt.days // 7).astype(int)
    first['cohort_month'] = first['cohort_week_start'].dt.to_period('M').astype(str)

    # âœ¨ ìˆ˜ì •: ì„ íƒëœ ì›”ì˜ ì½”í˜¸íŠ¸ë§Œ í•„í„°ë§
    cohorts_in_month = first[first['cohort_month'] == selected_month].copy()
    if cohorts_in_month.empty:
        st.warning(f"{selected_month}ì— ì‹œìž‘ëœ ì½”í˜¸íŠ¸ ê·¸ë£¹ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    # ë¼ë²¨ ìƒì„±
    iso = cohorts_in_month['cohort_week_start'].dt.isocalendar()
    cohorts_in_month['cohort_week_lbl'] = iso['year'].astype(str) + '-W' + iso['week'].astype(str).str.zfill(2)
    cohorts_in_month['week_of_month'] = ((cohorts_in_month['cohort_week_start'].dt.day - 1) // 7 + 1).astype(int)
    cohorts_in_month['cohort_mweek_lbl'] = (cohorts_in_month['cohort_month'] + ' W' + cohorts_in_month['week_of_month'].astype(str) + ' (' + cohorts_in_month['cohort_week_lbl'] + ')')
    
    cohort_size = cohorts_in_month.groupby('cohort_week_idx')['user_id'].nunique().rename('cohort_size')

    # (ì´í•˜ ê³„ì‚° ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼í•˜ë‚˜, 'cohorts_in_month'ë¥¼ ì‚¬ìš©)
    lab = src.merge(cohorts_in_month[['user_id','cohort_week_idx']], on='user_id', how='inner')
    if lab.empty: return None, None
    lab['age_w'] = lab['week_idx'] - lab['cohort_week_idx']
    lab = lab[(lab['age_w'] >= 0) & (lab['age_w'] <= max_age_w)].copy()
    cohort_weeks = np.sort(cohorts_in_month['cohort_week_idx'].unique())
    age_vals = np.arange(0, max_age_w+1)
    grid = pd.MultiIndex.from_product([cohort_weeks, age_vals], names=['cohort_week_idx','age_w']).to_frame(index=False)
    grid = grid[(grid['cohort_week_idx'] + grid['age_w']) <= last_week_idx].copy()
    counts = lab.groupby(['cohort_week_idx','age_w'])['user_id'].nunique().rename('active_users').reset_index()
    counts = grid.merge(counts, on=['cohort_week_idx','age_w'], how='left').fillna({'active_users':0})
    counts = counts.merge(cohort_size, on='cohort_week_idx', how='left')
    counts['retention_rate'] = counts['active_users'] / counts['cohort_size']
    heat = counts.pivot(index='cohort_week_idx', columns='age_w', values='retention_rate').sort_index().sort_index(axis=1)
    if 0 in heat.columns:
        heat = heat.loc[:, heat.columns != 0]
    lbl_map = (cohorts_in_month[['cohort_week_idx','cohort_mweek_lbl']].drop_duplicates().set_index('cohort_week_idx')['cohort_mweek_lbl'])
    cohort_idx = heat.index.copy()
    base_labels = cohort_idx.map(lbl_map)
    n_map = cohort_size.reindex(cohort_idx).fillna(0).astype(int).map(lambda x: f"{x:,}")
    row_labels = base_labels + ' Â· N=' + n_map
    heat.index = row_labels
    heat_pct = heat * 100

    # ížˆíŠ¸ë§µ ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(12, max(4, 0.7 * len(heat_pct))))
    sns.heatmap(
        heat_pct, annot=show_annotations, fmt=".1f", cmap="Blues",
        cbar_kws={'label':'ìž¬êµ¬ë§¤ìœ¨ (%)'}, linewidths=.3, linecolor='white', ax=ax)
    ax.set_title(f"{selected_month} ì‹œìž‘ ì£¼ê°„ ì½”í˜¸íŠ¸ ìž¬êµ¬ë§¤ìœ¨ (Ageâ‰¥1)", fontsize=16)
    ax.set_xlabel("ì²« êµ¬ë§¤ í›„ ê²½ê³¼ ì£¼ ìˆ˜")
    ax.set_ylabel("ì½”í˜¸íŠ¸ ì£¼ (YYYY-MM Wn (ISO ì£¼) Â· N)")
    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)
    fig.tight_layout()

    return fig, heat

@st.cache_data
def create_daily_cohort_heatmap(orders_df, selected_month, selected_week, max_age_d, show_annotations=True):
    """
    ì¼ ë‹¨ìœ„ ì½”í˜¸íŠ¸ ìž¬êµ¬ë§¤ìœ¨ì„ ê³„ì‚°í•˜ê³  ì›”/ì£¼ í•„í„°ë¥¼ ì ìš©í•˜ì—¬ ížˆíŠ¸ë§µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # --- ì œê³µí•´ì£¼ì‹  ì½”ë“œ ë¡œì§ì„ ìŠ¤íŠ¸ë¦¼ë¦¿ í•¨ìˆ˜ì— ë§žê²Œ ìˆ˜ì • ---
    
    # 0) ì›ì²œ ì •ë¦¬
    use_cols = [c for c in ['user_id', 'created_at', 'status'] if c in orders_df.columns]
    src = orders_df.loc[:, use_cols].copy()
    src = src[src['user_id'].notna()]
    src['status'] = src['status'].astype(str).str.strip().str.lower()
    src = src[src['status'] == 'complete'].drop(columns=['status'])
    if src.empty:
        st.warning("ìƒíƒœê°€ 'Complete'ì¸ ì£¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    src['created_at'] = pd.to_datetime(src['created_at'], utc=True, errors='coerce')
    src = src.dropna(subset=['created_at']).sort_values(['user_id','created_at'])
    if src.empty:
        st.warning("ìœ íš¨í•œ ì£¼ë¬¸ ì‹œê°„ì´ ìžˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    src['order_day'] = src['created_at'].dt.floor('D')
    last_day = src['order_day'].max()

    # 1) ì½”í˜¸íŠ¸(ì²« êµ¬ë§¤ ì¼ìž) ê³„ì‚°
    first = src.groupby('user_id', as_index=False)['order_day'].min().rename(columns={'order_day':'cohort_day'})
    first['cohort_month'] = first['cohort_day'].dt.to_period('M').astype(str)
    
    # ì£¼ì°¨(Week of Month) ê³„ì‚°
    week_start_day = first['cohort_day'].dt.normalize() - pd.to_timedelta(first['cohort_day'].dt.dayofweek, unit='D')
    first['cohort_week_of_month'] = ((week_start_day.dt.day - 1) // 7 + 1)

    # âœ¨ ìˆ˜ì •: ì„ íƒëœ ì›”/ì£¼ë¡œ ì½”í˜¸íŠ¸ í•„í„°ë§
    cohorts_filtered = first[first['cohort_month'] == selected_month]
    if selected_week != 'All':
        cohorts_filtered = cohorts_filtered[cohorts_filtered['cohort_week_of_month'] == selected_week]
    
    if cohorts_filtered.empty:
        st.warning(f"ì„ íƒëœ ì¡°ê±´ì— ë§žëŠ” ì½”í˜¸íŠ¸ ê·¸ë£¹ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
        
    cohort_size = cohorts_filtered.groupby('cohort_day')['user_id'].nunique().rename('cohort_size')

    # (ì´í•˜ ê³„ì‚° ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼í•˜ë‚˜, 'cohorts_filtered'ë¥¼ ì‚¬ìš©)
    lab = src.merge(cohorts_filtered[['user_id','cohort_day']], on='user_id', how='inner')
    lab['age_d'] = (lab['order_day'] - lab['cohort_day']).dt.days
    lab = lab[(lab['age_d'] >= 0) & (lab['age_d'] <= max_age_d)].copy()
    cohort_days = np.sort(cohorts_filtered['cohort_day'].unique())
    age_vals = np.arange(0, max_age_d+1)
    grid = pd.MultiIndex.from_product([cohort_days, age_vals], names=['cohort_day','age_d']).to_frame(index=False)
    grid['order_day'] = grid['cohort_day'] + pd.to_timedelta(grid['age_d'], unit='D')
    grid = grid[grid['order_day'] <= last_day].drop(columns=['order_day'])
    counts = lab.groupby(['cohort_day','age_d'])['user_id'].nunique().rename('active_users').reset_index()
    counts = grid.merge(counts, on=['cohort_day','age_d'], how='left').fillna({'active_users':0})
    counts = counts.merge(cohort_size, on='cohort_day', how='left')
    counts['retention_rate'] = counts['active_users'] / counts['cohort_size']

    # ì‹œê°í™” ë°ì´í„° ì¤€ë¹„ (Age=0 ì œì™¸)
    min_age_d = 1
    col_range = list(range(min_age_d, max_age_d + 1))
    heat = counts.pivot(index='cohort_day', columns='age_d', values='retention_rate').sort_index().reindex(columns=col_range)
    if heat.empty:
        st.warning("ì„ íƒëœ ì¡°ê±´ì˜ ìž¬êµ¬ë§¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
        
    # ë¼ë²¨ ìƒì„±
    def make_row_labels(days_index: pd.Index) -> pd.Series:
        idx = pd.Series(days_index, index=days_index)
        week_start = idx.dt.normalize() - pd.to_timedelta(idx.dt.dayofweek, unit='D')
        wom = ((week_start.dt.day - 1) // 7 + 1)
        dow_map = {0:'Mon', 1:'Tue', 2:'Wed', 3:'Thu', 4:'Fri', 5:'Sat', 6:'Sun'}
        dow_eng = idx.dt.dayofweek.map(dow_map)
        date_str = idx.dt.date.astype(str)
        return date_str + ' (' + dow_eng + ', W' + wom.astype(str) + ')'
        
    idx_dt = heat.index
    base_lbl = make_row_labels(idx_dt)
    n_map = cohort_size.reindex(idx_dt).fillna(0).astype(int).map(lambda x: f"{x:,}")
    heat.index = base_lbl + ' Â· N=' + n_map
    heat_pct = heat * 100

    # --- âœ¨âœ¨ ìˆ˜ì •ëœ ì‹œê°í™” ë¶€ë¶„ âœ¨âœ¨ ---

    # Figure ë†’ì´ ë™ì  ì¡°ì ˆ (í–‰ë‹¹ í• ë‹¹ ë†’ì´ë¥¼ 1.2ë¡œ ëŒ€í­ ì¦ê°€)
    base_height = 8
    row_height_factor = 1.2  # âœ¨ ìˆ˜ì •: ê° í–‰ì˜ ë†’ì´ë¥¼ ë”ìš± í™•ë³´
    fig_h = max(base_height, len(heat_pct.index) * row_height_factor)
    
    # Figure ë„ˆë¹„ ë™ì  ì¡°ì ˆ
    base_width = 12
    col_width_factor = 0.9
    fig_w = max(base_width, len(heat_pct.columns) * col_width_factor)
    
    fig, ax = plt.subplots(figsize=(fig_w, fig_h))
    
    month_max = heat.max().max() if not heat.empty else 0.01
    vmax = float(month_max * 100.0) if month_max > 0 else 1.0

    sns.heatmap(
        heat_pct, 
        annot=show_annotations, 
        fmt=".1f",
        cmap="Blues",
        vmin=0, 
        vmax=vmax,
        linewidths=.5, # ì„  êµµê¸°
        linecolor='white',
        cbar_kws={'label': 'ìž¬êµ¬ë§¤ìœ¨ (%)'}, 
        ax=ax,
        # âœ¨ ìˆ˜ì •: annot_kwsë¥¼ ì‚¬ìš©í•˜ì—¬ annotation ê¸€ê¼´ í¬ê¸°ë¥¼ 14ë¡œ ëŒ€í­ ì¦ê°€
        annot_kws={"fontsize": 20} 
    )
    ax.set_title(f"{selected_month} ì¼ì¼ ì½”í˜¸íŠ¸ ìž¬êµ¬ë§¤ìœ¨ (Ageâ‰¥1)", fontsize=18)
    ax.set_xlabel(f"ì²« êµ¬ë§¤ í›„ ê²½ê³¼ ì¼ ìˆ˜ ({min_age_d}â€“{max_age_d})", fontsize=30)
    ax.set_ylabel("ì½”í˜¸íŠ¸", fontsize=14)
    ax.tick_params(axis='both', which='major', labelsize=20) # ì¶• í‹± ë¼ë²¨ í¬ê¸° ì¼ê´„ ì¡°ì ˆ
    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)
    fig.tight_layout()

    return fig, heat


# --- âœ¨ [í•¨ìˆ˜ ì¶”ê°€] ìš”ì¼ë³„ ìž¬êµ¬ë§¤ ë¶„ì„ ---

# --- Helper í•¨ìˆ˜ë“¤ (ë¶„ì„ í•¨ìˆ˜ ë‚´ë¶€ì— í¬í•¨ì‹œí‚¤ê±°ë‚˜ ì „ì—­ìœ¼ë¡œ ë‘ ) ---
def fmt_pct3(x):
    if pd.isna(x): return "NA"
    return f"{x*100:.3f}%"

def agg_weekday(series_wd, df):
    g = (df.groupby(series_wd, as_index=False).agg(Repeat_Orders=('active_users','sum'), Exposure=('cohort_size','sum')))
    g = (g.set_index(series_wd.name).reindex(range(7)).fillna(0.0).reset_index().rename(columns={'index': series_wd.name}))
    g['Repeat_Rate'] = np.where(g['Exposure'] > 0, g['Repeat_Orders'] / g['Exposure'], np.nan)
    g['Weekday'] = g[series_wd.name].map({0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'})
    return g.sort_values(series_wd.name).reset_index(drop=True)

def set_padded_ylim(ax, *series, low_pad=0.15, high_pad=0.25, min_range=1e-6):
    vals = np.concatenate([np.array([v for v in s if pd.notna(v)]) for s in series if len(s)])
    if vals.size == 0: return
    y_min, y_max = float(vals.min()), float(vals.max())
    rng = max(y_max - y_min, min_range)
    ax.set_ylim(max(0.0, y_min - low_pad*rng), y_max + high_pad*rng)

@st.cache_data
def create_weekday_repeat_purchase_charts(orders_df, start_date, end_date):
    """
    ìš”ì¼ë³„ ìž¬êµ¬ë§¤ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  3ê°œì˜ ì°¨íŠ¸ë¥¼ í¬í•¨í•œ Figureë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # --- ë°ì´í„° ì¤€ë¹„ ---
    # (ì´ì „ ê³ ê¸‰ ì½”í˜¸íŠ¸ ë¶„ì„ì—ì„œ ì‚¬ìš©í•œ 'counts' ë°ì´í„°í”„ë ˆìž„ì„ ìƒì„±í•˜ëŠ” ë¡œì§ì„ ìž¬í™œìš©)
    src = orders_df[orders_df['status'].str.lower() == 'complete'].copy()
    src['created_at'] = pd.to_datetime(src['created_at'], utc=True, errors='coerce')
    src = src.dropna(subset=['created_at']).sort_values(['user_id','created_at'])
    start_datetime = pd.to_datetime(start_date).tz_localize('UTC')
    end_datetime = pd.to_datetime(end_date).tz_localize('UTC') + pd.Timedelta(days=1)
    src = src[(src['created_at'] >= start_datetime) & (src['created_at'] < end_datetime)]
    if src.empty:
        st.warning("ì„ íƒëœ ê¸°ê°„ì— 'Complete' ìƒíƒœì˜ ì£¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None
        
    src['order_day'] = src['created_at'].dt.floor('D')
    first = src.groupby('user_id', as_index=False)['order_day'].min().rename(columns={'order_day':'cohort_day'})
    lab = src.merge(first[['user_id','cohort_day']], on='user_id', how='inner')
    lab['age_d'] = (lab['order_day'] - lab['cohort_day']).dt.days
    cohort_size = first.groupby('cohort_day')['user_id'].nunique().rename('cohort_size')
    counts = lab.groupby(['cohort_day','age_d'])['user_id'].nunique().rename('active_users').reset_index()
    counts = counts.merge(cohort_size, on='cohort_day', how='left')
    
    # --- ì œê³µí•´ì£¼ì‹  ì½”ë“œ ë¡œì§ (Prep, Aggregations) ---
    df = counts.copy()
    df = df[df['age_d'] >= 1].copy()
    if df.empty:
        st.warning("ìž¬êµ¬ë§¤ ë°ì´í„°(Ageâ‰¥1)ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None
        
    df['cohort_day'] = pd.to_datetime(df['cohort_day'], utc=True, errors='coerce')
    df = df.dropna(subset=['cohort_day'])
    df['repurch_date'] = df['cohort_day'] + pd.to_timedelta(df['age_d'], unit='D')
    df['order_wd'] = df['repurch_date'].dt.dayofweek
    df['cohort_wd'] = df['cohort_day'].dt.dayofweek
    
    order_grp = agg_weekday(df['order_wd'], df)
    cohort_grp = agg_weekday(df['cohort_wd'], df)
    
    # --- ì‹œê°í™” ---
    fig, (ax_bars_ord, ax_bars_coh, ax_line_both) = plt.subplots(1, 3, figsize=(18, 5.5), constrained_layout=True)
    x = np.arange(7)
    week_labels = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']

    # Plot 1: Order bars
    bars1 = ax_bars_ord.bar(x, order_grp['Repeat_Orders'], color='#4C78A8', alpha=0.9)
    ax_bars_ord.set(title="ìž¬êµ¬ë§¤ ë°œìƒ ìš”ì¼ ë¶„í¬", ylabel="ìž¬êµ¬ë§¤ ê±´ìˆ˜", xticks=x, xticklabels=week_labels)
    ax_bars_ord.grid(axis='y', linestyle=':', alpha=0.5)

    # Plot 2: Cohort bars
    bars2 = ax_bars_coh.bar(x, cohort_grp['Repeat_Orders'], color='#E45756', alpha=0.9)
    ax_bars_coh.set(title="ì²« êµ¬ë§¤ ìš”ì¼ë³„ ìž¬êµ¬ë§¤ ê±´ìˆ˜", ylabel="ìž¬êµ¬ë§¤ ê±´ìˆ˜", xticks=x, xticklabels=week_labels)
    ax_bars_coh.grid(axis='y', linestyle=':', alpha=0.5)

    # Plot 3: Combined lines
    order_line, = ax_line_both.plot(x, order_grp['Repeat_Rate'], marker='o', color='#4C78A8', label='ìž¬êµ¬ë§¤ì¼ ê¸°ì¤€')
    cohort_line, = ax_line_both.plot(x, cohort_grp['Repeat_Rate'], marker='o', color='#E45756', label='ì²«êµ¬ë§¤ì¼ ê¸°ì¤€')
    ax_line_both.set(title="ìš”ì¼ë³„ ìž¬êµ¬ë§¤ìœ¨ (ìž¬êµ¬ë§¤ì¼ vs ì²«êµ¬ë§¤ì¼)", ylabel="ìž¬êµ¬ë§¤ìœ¨ (%)", xticks=x, xticklabels=week_labels)
    ax_line_both.yaxis.set_major_formatter(PercentFormatter(xmax=1.0, decimals=1))
    ax_line_both.grid(axis='y', linestyle=':', alpha=0.5)
    set_padded_ylim(ax_line_both, order_grp['Repeat_Rate'].values, cohort_grp['Repeat_Rate'].values)
    ax_line_both.legend(loc='best')
    
    fig.suptitle("ìš”ì¼ë³„ ìž¬êµ¬ë§¤ íŒ¨í„´ ë¶„ì„ (ìž¬êµ¬ë§¤ ê±´ìˆ˜ ë° ë¹„ìœ¨, Ageâ‰¥1)", fontsize=16, fontweight='bold')
    
    return fig, order_grp, cohort_grp


# Helper í•¨ìˆ˜ë“¤
def fmt_pct3(x):
    if pd.isna(x): return "NA"
    return f"{x*100:.3f}%"

@st.cache_data
def create_weekday_weekend_chart(orders_df, start_date, end_date):
    """
    ì„ íƒëœ ê¸°ê°„ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì£¼ì¤‘/ì£¼ë§ ìž¬êµ¬ë§¤ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.
    """
    # --- ë°ì´í„° ì¤€ë¹„ (ê¸°ì¡´ ì½”í˜¸íŠ¸ ë¶„ì„ ë¡œì§ ìž¬í™œìš©í•˜ì—¬ 'counts' ìƒì„±) ---
    src = orders_df[orders_df['status'].str.lower() == 'complete'].copy()
    src['created_at'] = pd.to_datetime(src['created_at'], utc=True, errors='coerce')
    src = src.dropna(subset=['created_at']).sort_values(['user_id','created_at'])
    start_datetime = pd.to_datetime(start_date).tz_localize('UTC')
    end_datetime = pd.to_datetime(end_date).tz_localize('UTC') + pd.Timedelta(days=1)
    src = src[(src['created_at'] >= start_datetime) & (src['created_at'] < end_datetime)]
    if src.empty:
        st.warning("ì„ íƒëœ ê¸°ê°„ì— 'Complete' ìƒíƒœì˜ ì£¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
        
    src['order_day'] = src['created_at'].dt.floor('D')
    first = src.groupby('user_id', as_index=False)['order_day'].min().rename(columns={'order_day':'cohort_day'})
    lab = src.merge(first[['user_id','cohort_day']], on='user_id', how='inner')
    lab['age_d'] = (lab['order_day'] - lab['cohort_day']).dt.days
    cohort_size = first.groupby('cohort_day')['user_id'].nunique().rename('cohort_size')
    counts = lab.groupby(['cohort_day','age_d'])['user_id'].nunique().rename('active_users').reset_index()
    counts = counts.merge(cohort_size, on='cohort_day', how='left')
    
    # --- ì œê³µí•´ì£¼ì‹  ì½”ë“œ ë¡œì§ (Prep, Aggregations) ---
    df = counts.copy()
    df = df[df['age_d'] >= 1].copy()
    if df.empty:
        st.warning("ìž¬êµ¬ë§¤ ë°ì´í„°(Ageâ‰¥1)ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
        
    df['cohort_day'] = pd.to_datetime(df['cohort_day'], utc=True, errors='coerce')
    df = df.dropna(subset=['cohort_day'])
    df['repurch_date'] = df['cohort_day'] + pd.to_timedelta(df['age_d'], unit='D')
    df['repurch_wd'] = df['repurch_date'].dt.dayofweek
    df['is_weekend'] = df['repurch_wd'].isin({5,6})

    g = (df.groupby('is_weekend', as_index=False)
           .agg(Repeaters=('active_users','sum'), Exposure=('cohort_size','sum')))
    g['Rate'] = np.where(g['Exposure']>0, g['Repeaters']/g['Exposure'], np.nan)
    g['Group'] = np.where(g['is_weekend'], 'ì£¼ë§ (í† +ì¼)', 'ì£¼ì¤‘ (ì›”â€“ê¸ˆ)')
    g = g.sort_values('is_weekend').reset_index(drop=True)

    # í…Œì´ë¸” ìƒì„±
    tbl = pd.DataFrame({
        'êµ¬ë¶„': g['Group'],
        'ìž¬êµ¬ë§¤ìž ìˆ˜': g['Repeaters'].astype(int),
        'ì „ì²´ ì½”í˜¸íŠ¸ í¬ê¸°': g['Exposure'].astype(int),
        'ìž¬êµ¬ë§¤ìœ¨ (%)': (g['Rate']*100).round(3)
    })

    # ë§‰ëŒ€ ì°¨íŠ¸ ìƒì„±
    fig, ax = plt.subplots(figsize=(7, 5))
    BAR_COLORS = ['#A3C4F3', '#FDE2A7']
    bars = ax.bar(g['Group'], g['Rate'], color=BAR_COLORS, edgecolor='none')
    
    ymax = float(np.nanmax(g['Rate'])) if len(g) else 0.0
    pad = ymax * 0.15 if ymax > 0 else 0.01
    ax.set_ylim(0, ymax + pad)

    for rect, r in zip(bars, g['Rate']):
        ax.annotate(f"{r*100:.2f}%", xy=(rect.get_x() + rect.get_width()/2, r),
                    xytext=(0, 6), textcoords='offset points', ha='center', va='bottom')
                    
    ax.yaxis.set_major_formatter(PercentFormatter(xmax=1.0, decimals=1))
    ax.set_ylabel("ìž¬êµ¬ë§¤ìœ¨ (%)")
    ax.set_title("ì£¼ì¤‘ vs ì£¼ë§ ìž¬êµ¬ë§¤ìœ¨ ë¹„êµ (Age â‰¥ 1)", fontsize=14)
    ax.grid(axis='y', linestyle=':', alpha=0.35)
    fig.tight_layout()

    return fig, tbl


@st.cache_data
def create_weekly_cohort_heatmap(orders_df, selected_month, selected_week, max_age_w, show_annotations=True):
    """
    ì„ íƒëœ ì›”/ì£¼ì— ì‹œìž‘ëœ ì£¼ê°„ ì½”í˜¸íŠ¸ì˜ ìž¬êµ¬ë§¤ìœ¨ì„ ë¶„ì„í•˜ê³  ížˆíŠ¸ë§µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # --- ì œê³µí•´ì£¼ì‹  ì½”ë“œ ë¡œì§ì„ ìŠ¤íŠ¸ë¦¼ë¦¿ í•¨ìˆ˜ì— ë§žê²Œ ìˆ˜ì • ---
    
    # 0) ì›ì²œ ì •ë¦¬
    use_cols = [c for c in ['user_id', 'created_at', 'status'] if c in orders_df.columns]
    src = orders_df.loc[:, use_cols].copy()
    src = src[src['user_id'].notna()]
    src['status'] = src['status'].astype(str).str.strip().str.lower()
    src = src[src['status'] == 'complete'].drop(columns=['status'])
    if src.empty:
        st.warning("ìƒíƒœê°€ 'Complete'ì¸ ì£¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    src['created_at'] = pd.to_datetime(src['created_at'], utc=True, errors='coerce')
    src = src.dropna(subset=['created_at']).sort_values(['user_id','created_at'])
    if src.empty:
        st.warning("ìœ íš¨í•œ ì£¼ë¬¸ ì‹œê°„ì´ ìžˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
        
    REF = pd.Timestamp('1970-01-05', tz='UTC')
    src['week_start'] = src['created_at'].dt.normalize() - pd.to_timedelta(src['created_at'].dt.dayofweek, unit='D')
    src['week_idx'] = ((src['week_start'] - REF).dt.days // 7).astype(int)
    last_week_idx = int(src['week_idx'].max())

    # 1) ì²« êµ¬ë§¤(ì½”í˜¸íŠ¸) ê³„ì‚° ë° ë¼ë²¨ ìƒì„±
    first = src.groupby('user_id', as_index=False)['created_at'].min().rename(columns={'created_at':'first_time'})
    first['cohort_week_start'] = first['first_time'].dt.normalize() - pd.to_timedelta(first['first_time'].dt.dayofweek, unit='D')
    first['cohort_week_idx'] = ((first['cohort_week_start'] - REF).dt.days // 7).astype(int)
    iso = first['cohort_week_start'].dt.isocalendar()
    first['cohort_year'] = iso['year']
    first['cohort_week_lbl'] = iso['year'].astype(str) + '-W' + iso['week'].astype(str).str.zfill(2)
    first['cohort_month'] = first['cohort_week_start'].dt.to_period('M').astype(str)
    first['week_of_month'] = ((first['cohort_week_start'].dt.day - 1) // 7 + 1).astype(int)
    first['cohort_mweek_lbl'] = (first['cohort_month'] + ' W' + first['week_of_month'].astype(str) + ' (' + first['cohort_week_lbl'] + ')')
    
    # âœ¨ ìˆ˜ì •: ì„ íƒëœ ì›”/ì£¼ë¡œ ì½”í˜¸íŠ¸ í•„í„°ë§
    cohorts_filtered = first[first['cohort_month'] == selected_month]
    if selected_week != 'All':
        cohorts_filtered = cohorts_filtered[cohorts_filtered['week_of_month'] == selected_week]
    
    if cohorts_filtered.empty:
        st.warning(f"ì„ íƒëœ ì¡°ê±´ì— ë§žëŠ” ì½”í˜¸íŠ¸ ê·¸ë£¹ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
        
    cohort_size = cohorts_filtered.groupby('cohort_week_idx')['user_id'].nunique().rename('cohort_size')

    # (ì´í•˜ ê³„ì‚° ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼í•˜ë‚˜, 'cohorts_filtered'ë¥¼ ì‚¬ìš©)
    lab = src.merge(cohorts_filtered[['user_id','cohort_week_idx']], on='user_id', how='inner')
    if lab.empty: return None, None
    lab['age_w'] = lab['week_idx'] - lab['cohort_week_idx']
    lab = lab[(lab['age_w'] >= 0) & (lab['age_w'] <= max_age_w)].copy()
    cohort_weeks = np.sort(cohorts_filtered['cohort_week_idx'].unique())
    age_vals = np.arange(0, max_age_w+1)
    grid = pd.MultiIndex.from_product([cohort_weeks, age_vals], names=['cohort_week_idx','age_w']).to_frame(index=False)
    grid = grid[(grid['cohort_week_idx'] + grid['age_w']) <= last_week_idx].copy()
    counts = lab.groupby(['cohort_week_idx','age_w'])['user_id'].nunique().rename('active_users').reset_index()
    counts = grid.merge(counts, on=['cohort_week_idx','age_w'], how='left').fillna({'active_users':0})
    counts = counts.merge(cohort_size, on='cohort_week_idx', how='left')
    counts['retention_rate'] = counts['active_users'] / counts['cohort_size']
    heat = counts.pivot(index='cohort_week_idx', columns='age_w', values='retention_rate').sort_index().sort_index(axis=1)
    if 0 in heat.columns:
        heat = heat.loc[:, heat.columns != 0]

    lbl_map = (cohorts_filtered[['cohort_week_idx','cohort_mweek_lbl']].drop_duplicates().set_index('cohort_week_idx')['cohort_mweek_lbl'])
    cohort_idx = heat.index.copy()
    base_labels = cohort_idx.map(lbl_map)
    n_map = cohort_size.reindex(cohort_idx).fillna(0).astype(int).map(lambda x: f"{x:,}")
    row_labels = base_labels + ' Â· N=' + n_map
    heat.index = row_labels
    heat_pct = heat * 100

    # ížˆíŠ¸ë§µ ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(12, max(4, 0.7 * len(heat_pct))))
    sns.heatmap(
        heat_pct, annot=show_annotations, fmt=".1f", cmap="Blues",
        cbar_kws={'label':'ìž¬êµ¬ë§¤ìœ¨ (%)'}, linewidths=.3, linecolor='white', ax=ax)
    ax.set_title(f"{selected_month} (W{selected_week if selected_week != 'All' else 'ì „ì²´'}) ì£¼ê°„ ì½”í˜¸íŠ¸ ìž¬êµ¬ë§¤ìœ¨", fontsize=16)
    ax.set_xlabel("ì²« êµ¬ë§¤ í›„ ê²½ê³¼ ì£¼ ìˆ˜")
    ax.set_ylabel("ì½”í˜¸íŠ¸ ì£¼ (YYYY-MM Wn (ISO ì£¼) Â· N)")
    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)
    fig.tight_layout()

    return fig, heat



# --- ðŸŽ¨ ë©”ì¸ ëŒ€ì‹œë³´ë“œ ë ˆì´ì•„ì›ƒ ---

st.set_page_config(layout="wide", page_title="êµ¬ë§¤ ë¶„ì„")
st.title("ðŸ›ï¸ ì‚¬ìš©ìž êµ¬ë§¤ íŒ¨í„´ ë¶„ì„")

# --- ë°ì´í„° ë¡œë”© ---
all_data = load_all_data()

if not all_data :
    st.error("ì£¼ë¬¸(order_items) ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
else:

    events = all_data["events"]
    order_items = all_data["order_items"]
    users = all_data["users"]
    orders = all_data["orders"]
    products = all_data["products"]
    products_master = products.copy()


    events_master = events.copy()
    order_items_master = order_items.copy()
    users_master = users.copy()
    orders_master = orders.copy()

    raw_data_schema={
            'user_id': 'session_id', 'event_name': 'event_type', 'event_timestamp': 'created_at'
        }
    
    valid_status = ['Complete', 'Returned', 'Cancelled']
    valid_orders = order_items[order_items['status'].isin(valid_status)].copy()

    # ìœ ì €ë³„ êµ¬ë§¤ ë‚´ì—­ ì •ë ¬
    valid_orders = valid_orders.sort_values(['user_id', 'created_at'])
    

    valid_status = ['Complete', 'Returned', 'Cancelled']
    valid_orders = order_items[order_items['status'].isin(valid_status)].copy()
    user_purchase_counts = valid_orders.groupby('user_id')['order_id'].nunique()

    st.header("ì‚¬ìš©ìžë³„ êµ¬ë§¤ íšŸìˆ˜ ë¶„í¬")
    st.write("ê° ì‚¬ìš©ìžê°€ ëª‡ ë²ˆì˜ êµ¬ë§¤ë¥¼ í–ˆëŠ”ì§€ ë¶„í¬ë¥¼ í†µí•´ ì¶©ì„± ê³ ê°ê³¼ ì¼íšŒì„± ê³ ê°ì˜ ë¹„ìœ¨ì„ íŒŒì•…í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")

    order_items_master = all_data["order_items"].copy()
    products_master = all_data["products"].copy()

    # --- ðŸŽ¨ ë©”ì¸ ëŒ€ì‹œë³´ë“œ ë ˆì´ì•„ì›ƒ ---
    st.title("ê³ ê° ë¦¬í…ì…˜ ë¶„ì„ (Cohort)")

            # --- ì‚¬ì´ë“œë°”: ì»¨íŠ¸ë¡¤ íŒ¨ë„ ---
    st.sidebar.header("âš™ï¸ ì»¨íŠ¸ë¡¤ íŒ¨ë„")
    st.sidebar.subheader("ðŸ“… ë‚ ì§œ í•„í„°")
    start_date = st.sidebar.date_input("ì‹œìž‘ì¼", order_items_master['created_at'].min())
    end_date = st.sidebar.date_input("ì¢…ë£Œì¼", order_items_master['created_at'].max())
            
    st.sidebar.divider()
    st.sidebar.subheader("ðŸ“Š ì°¨íŠ¸ ì˜µì…˜")
    # max_age_option = st.sidebar.slider("ìµœëŒ€ ê²½ê³¼ ê°œì›” ìˆ˜:", 1, 24, 12, help="ížˆíŠ¸ë§µì— í‘œì‹œí•  ìµœëŒ€ ìž¬êµ¬ë§¤ ê²½ê³¼ ê°œì›” ìˆ˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.")
    show_annotations = st.sidebar.checkbox("ížˆíŠ¸ë§µì— ë¦¬í…ì…˜ ê°’(%) í‘œì‹œ", value=True)

    tab1, tab2, tab3  = st.tabs(["ðŸŽ¯ ì‚¬ìš©ìžë³„ êµ¬ë§¤ íšŸìˆ˜ ë¶„í¬","ðŸ“ˆ ì›”ë³„ ì²« êµ¬ë§¤ ê³ ê° ìž¬êµ¬ë§¤ìœ¨ ë¶„ì„", "ðŸŒŠ ìš”ì¼ì— ë”°ë¥¸ ìž¬êµ¬ë§¤ íŒ¨í„´ ì‹¬ì¸µ ë¶„ì„"])


    with tab1:
        st.subheader("ì „ì²´ ìœ ìž… ê²½ë¡œ ë¶„í¬")

        if not all_data or "order_items" not in all_data:
            st.error("ì£¼ë¬¸(order_items) ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        else:
            order_items = all_data["order_items"]
            
            st.header("ì‚¬ìš©ìžë³„ êµ¬ë§¤ íšŸìˆ˜ ë¶„í¬")
            st.write("ê° ì‚¬ìš©ìžê°€ ëª‡ ë²ˆì˜ êµ¬ë§¤ë¥¼ í–ˆëŠ”ì§€ ë¶„í¬ë¥¼ í†µí•´ ì¶©ì„± ê³ ê°ê³¼ ì¼íšŒì„± ê³ ê°ì˜ ë¹„ìœ¨ì„ íŒŒì•…í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")

            # ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
            dist_fig, dist_data = create_purchase_distribution_chart(order_items)
            
            if dist_fig:
                # ì»¬ëŸ¼ì„ ì‚¬ìš©í•´ ì°¨íŠ¸ì™€ ë°ì´í„°ë¥¼ ë‚˜ëž€ížˆ í‘œì‹œ
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.pyplot(dist_fig)
                with col2:
                    st.write("#### ë°ì´í„° ìš”ì•½")
                    st.dataframe(dist_data)

        if not all_data:
            st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        else:
            

            # --- âœ¨âœ¨ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ âœ¨âœ¨ ---

            # --- ì²« ë²ˆì§¸ ë¶„ì„: ì „ì²´ ë¦¬í…ì…˜ ---
            st.subheader("ðŸ—“ï¸ ì „ì²´ ê³ ê° ë¦¬í…ì…˜")
            
            # ë‚ ì§œ í•„í„°ë§
            start_datetime = pd.to_datetime(start_date).tz_localize('UTC')
            end_datetime = pd.to_datetime(end_date).tz_localize('UTC') + pd.Timedelta(days=1)
            filtered_orders = order_items_master[
                (order_items_master['created_at'] >= start_datetime) & 
                (order_items_master['created_at'] < end_datetime)
            ]

            # ì „ì²´ ë¦¬í…ì…˜ ì°¨íŠ¸ ìƒì„± ë° í‘œì‹œ
            heatmap_fig, cohort_df = create_retention_heatmap(filtered_orders, show_annotations)
            if heatmap_fig:
                st.pyplot(heatmap_fig)
                with st.expander("ìƒì„¸ ë°ì´í„° ë³´ê¸°"):
                    st.dataframe(cohort_df.style.format("{:.2%}"))
            else:
                st.warning("ì„ íƒëœ ê¸°ê°„ì— ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            # --- ë‘ ë¶„ì„ ì‚¬ì´ì— êµ¬ë¶„ì„  ì¶”ê°€ ---
            st.divider()

            # --- ë‘ ë²ˆì§¸ ë¶„ì„: ì¹´í…Œê³ ë¦¬ë³„ ë¦¬í…ì…˜ ---
            st.subheader("ðŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ë³„ ê³ ê° ë¦¬í…ì…˜")
            
            # ì¹´í…Œê³ ë¦¬ ì„ íƒ í•„í„° (ë„ˆë¹„ ì¡°ì ˆì„ ìœ„í•´ ì»¬ëŸ¼ ì‚¬ìš©)
            filter_col, _ = st.columns([1, 2])
            with filter_col:
                available_categories = sorted(products_master['category'].unique())
                selected_category = st.selectbox(
                    "ë¶„ì„í•  ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:", 
                    available_categories,
                    index=available_categories.index('Intimates') if 'Intimates' in available_categories else 0
                )
            
            # ì¹´í…Œê³ ë¦¬ë³„ ë¦¬í…ì…˜ ì°¨íŠ¸ ìƒì„± ë° í‘œì‹œ
            cat_heatmap_fig, cat_cohort_df = create_category_cohort_heatmap(
                order_items_master, 
                products_master,
                selected_category,
                show_annotations
            )
            if cat_heatmap_fig:
                st.pyplot(cat_heatmap_fig)
                with st.expander("ìƒì„¸ ë°ì´í„° ë³´ê¸°"):
                    st.dataframe(cat_cohort_df.style.format("{:.2%}"))
            else:
                st.warning(f"'{selected_category}' ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        

    


    with tab2:
        st.subheader("ì›”ë³„ ì²« êµ¬ë§¤ ê³ ê° ìž¬êµ¬ë§¤ìœ¨ ë¶„ì„")

        filter_col, _ = st.columns([1, 2])
        with filter_col:
            # 2. st.sliderë¥¼ ì‚¬ìš©í•˜ì—¬ í•„í„°ë¥¼ ë©”ì¸ íŽ˜ì´ì§€ì— ë°°ì¹˜í•©ë‹ˆë‹¤.
            max_age_option = st.slider(
                "ìµœëŒ€ ê²½ê³¼ ê°œì›” ìˆ˜:", 
                min_value=1, 
                max_value=12, 
                value=12, 
                help="ížˆíŠ¸ë§µì— í‘œì‹œí•  ìµœëŒ€ ìž¬êµ¬ë§¤ ê²½ê³¼ ê°œì›” ìˆ˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤."
            )
        
        # ê³ ê¸‰ ì½”í˜¸íŠ¸ ë¶„ì„ í•¨ìˆ˜ í˜¸ì¶œ
        cohort_fig, cohort_df = create_advanced_cohort_heatmap(
            order_items_master, 
            max_age_option, 
            show_annotations
        )

        if cohort_fig:
            st.pyplot(cohort_fig)
            with st.expander("ìƒì„¸ ë°ì´í„° ë³´ê¸°"):
                # .style.format()ì€ PeriodIndexì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìžˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                try:
                    st.dataframe(cohort_df.style.format("{:.2%}"))
                except Exception:
                    st.dataframe(cohort_df)
        else:
            # í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ st.warningìœ¼ë¡œ ì´ë¯¸ ë©”ì‹œì§€ë¥¼ ë³´ì—¬ì£¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” pass
            pass

                # âœ¨ ìˆ˜ì •: í•¨ìˆ˜ í˜¸ì¶œ ì‹œ year ì¸ìž ì œê±°
        repeat_fig, repeat_df = create_repeat_purchaser_chart(order_items_master)

        if repeat_fig:
            st.pyplot(repeat_fig)
            with st.expander("ìƒì„¸ ë°ì´í„° ë³´ê¸°"):
                st.dataframe(repeat_df[['returning_users','purchasers','repeat_purchaser_rate']])
        else:
            # í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì´ë¯¸ ê²½ê³  ë©”ì‹œì§€ë¥¼ í‘œì‹œí•¨
            pass

        st.divider()

        st.subheader("ì£¼ê°„ ì½”í˜¸íŠ¸ ìž¬êµ¬ë§¤ìœ¨")



        # --- í•„í„° ìœ„ì ¯ ---
        # ë°ì´í„°ì—ì„œ ì„ íƒ ê°€ëŠ¥í•œ ì›” ëª©ë¡ ë™ì  ìƒì„±
        temp_df = order_items_master.copy()
        temp_df['cohort_month'] = pd.to_datetime(temp_df['created_at']).dt.to_period('M').astype(str)
        available_months = sorted(temp_df['cohort_month'].unique(), reverse=True)
        
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            selected_month = st.selectbox("ë¶„ì„í•  ì½”í˜¸íŠ¸ ì›” ì„ íƒ:", available_months)
        with col2:
            week_options = ['All'] + list(range(1, 6))
            selected_week = st.selectbox("ì£¼ì°¨ í•„í„° (Wn):", week_options, help="í•´ë‹¹ ì›”ì˜ në²ˆì§¸ ì£¼ì— ì‹œìž‘ëœ ì½”í˜¸íŠ¸ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.")

        col_slider, _ = st.columns([2, 1])
        with col_slider:
            max_age_option = st.slider("ìµœëŒ€ ê²½ê³¼ ì£¼ ìˆ˜:", 1, 52, 12)

        show_annotations = st.checkbox("ížˆíŠ¸ë§µì— ê°’(%) í‘œì‹œ", value=True)
        st.divider()

        # --- ì°¨íŠ¸ ìƒì„± ë° í‘œì‹œ ---
        if selected_month:
            weekly_fig, weekly_df = create_weekly_cohort_heatmap(
                order_items_master, 
                selected_month,
                selected_week,
                max_age_option, 
                show_annotations
            )

            if weekly_fig:
                st.pyplot(weekly_fig)
                with st.expander("ìƒì„¸ ë°ì´í„° ë³´ê¸°"):
                    st.dataframe(weekly_df.style.format("{:.2%}"))
            else:
                # í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì´ë¯¸ ê²½ê³  ë©”ì‹œì§€ë¥¼ í‘œì‹œí•¨
                pass

        st.divider()
        st.subheader("ì¼ë³„ ì½”í˜¸íŠ¸ ìž¬êµ¬ë§¤ìœ¨")

        # --- í•„í„° ìœ„ì ¯ ---
        # ë°ì´í„°ì—ì„œ ì„ íƒ ê°€ëŠ¥í•œ ì›” ëª©ë¡ ìƒì„±
        temp_df = order_items_master.copy()
        temp_df['cohort_month'] = pd.to_datetime(temp_df['created_at']).dt.to_period('M').astype(str)
        available_months = sorted(temp_df['cohort_month'].unique(), reverse=True)
        
        temp_df = order_items_master.copy()
        temp_df['cohort_month'] = pd.to_datetime(temp_df['created_at']).dt.to_period('M').astype(str)
        available_months = sorted(temp_df['cohort_month'].unique(), reverse=True)
        
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            selected_month2 = st.selectbox("ë¶„ì„í•  ì½”í˜¸íŠ¸ ì›” ì„ íƒ:", available_months,key='source_selectbox_tab2')
        with col2:
            # ì›”~W5, ì „ì²´(All)
            week_options = ['All'] + [i for i in range(1, 6)]
            selected_week = st.selectbox("ì£¼ì°¨ í•„í„° (Wn):", week_options)

        col_slider, _ = st.columns([2, 1])
        with col_slider:
            max_age_option = st.slider("ìµœëŒ€ ê²½ê³¼ ì¼ ìˆ˜:", 1, 60, 30)

        st.divider()

        # --- ì°¨íŠ¸ ìƒì„± ë° í‘œì‹œ ---
        if selected_month:
            daily_fig, daily_df = create_daily_cohort_heatmap(
                order_items_master, 
                selected_month2,
                selected_week,
                max_age_option, 
                show_annotations
            )

            if daily_fig:
                st.pyplot(daily_fig)
                with st.expander("ìƒì„¸ ë°ì´í„° ë³´ê¸°"):
                    st.dataframe(daily_df.style.format("{:.2%}"))
            else:
                # í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì´ë¯¸ ê²½ê³  ë©”ì‹œì§€ë¥¼ í‘œì‹œí•¨
                pass

        

            

    
    with tab3:
        st.subheader("ìš”ì¼ì— ë”°ë¥¸ ìž¬êµ¬ë§¤ íŒ¨í„´ ì‹¬ì¸µ ë¶„ì„")
        st.info("ì²« êµ¬ë§¤ ìš”ì¼ ë˜ëŠ” ì‹¤ì œ ìž¬êµ¬ë§¤ê°€ ë°œìƒí•œ ìš”ì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ìž¬êµ¬ë§¤ ê±´ìˆ˜ì™€ ë¹„ìœ¨ì˜ ì°¨ì´ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

        # ìƒˆë¡œ ë§Œë“  í•¨ìˆ˜ í˜¸ì¶œ
        weekday_fig, order_data, cohort_data = create_weekday_repeat_purchase_charts(order_items_master, start_date, end_date)

        if weekday_fig:
            st.pyplot(weekday_fig)
            
            with st.expander("ìƒì„¸ ë°ì´í„° ë³´ê¸°"):
                col1, col2 = st.columns(2)
                with col1:
                    st.write("#### ìž¬êµ¬ë§¤ ë°œìƒ ìš”ì¼ ê¸°ì¤€")
                    st.dataframe(order_data[['Weekday', 'Repeat_Orders', 'Exposure', 'Repeat_Rate']].style.format({'Repeat_Rate': '{:.2%}'}))
                with col2:
                    st.write("#### ì²« êµ¬ë§¤ ìš”ì¼ ê¸°ì¤€")
                    st.dataframe(cohort_data[['Weekday', 'Repeat_Orders', 'Exposure', 'Repeat_Rate']].style.format({'Repeat_Rate': '{:.2%}'}))
        else:
            # í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì´ë¯¸ ê²½ê³  ë©”ì‹œì§€ë¥¼ í‘œì‹œí•¨
            pass

        st.info("ì²« êµ¬ë§¤ ìš”ì¼ ë˜ëŠ” ì‹¤ì œ ìž¬êµ¬ë§¤ê°€ ë°œìƒí•œ ìš”ì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ìž¬êµ¬ë§¤ ê±´ìˆ˜ì™€ ë¹„ìœ¨ì˜ ì°¨ì´ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
        
        # --- âœ¨ [ì„¹ì…˜ ì¶”ê°€] ì£¼ì¤‘/ì£¼ë§ ìž¬êµ¬ë§¤ìœ¨ ë¹„êµ ---
        weekday_fig, weekday_tbl = create_weekday_weekend_chart(order_items_master, start_date, end_date)
        
        if weekday_fig:
            col1, col2 = st.columns([1, 2])
            with col1:
                st.write("#### ë¶„ì„ ìš”ì•½ í…Œì´ë¸”")
                st.dataframe(weekday_tbl, hide_index=True)
            with col2:
                st.pyplot(weekday_fig)
        else:
            st.warning("ì£¼ì¤‘/ì£¼ë§ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")


    
    